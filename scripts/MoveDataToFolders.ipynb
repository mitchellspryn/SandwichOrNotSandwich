{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "import random\n",
    "\n",
    "sandwich_dir_names = \\\n",
    "    [\\\n",
    "         'croque_madam',\\\n",
    "         'hamburger',\\\n",
    "         'lobster_roll_sandwich',\\\n",
    "         'pulled_pork_sandwich',\\\n",
    "         'club_sandwich',\\\n",
    "         'grilled_cheese_sandwich',\\\n",
    "         'hot_dog',\\\n",
    "         'tacos'\\\n",
    "    ]\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_directories =\\\n",
    "    [\\\n",
    "        '../data/images/train/sandwich',\\\n",
    "        '../data/images/val/sandwich',\\\n",
    "        '../data/images/test/sandwich',\\\n",
    "        '../data/images/train/not_sandwich',\\\n",
    "        '../data/images/val/not_sandwich',\\\n",
    "        '../data/images/test/not_sandwich'\\\n",
    "    ]\n",
    "\n",
    "for directory in output_directories:\n",
    "    if not os.path.isdir(directory):\n",
    "        os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sandwich_files = []\n",
    "not_sandwich_files = []\n",
    "\n",
    "for item in os.walk('../data'):\n",
    "    if ('train' not in item[0] and 'test' not in item[0]):\n",
    "        filenames = [(item[0], filename) for filename in item[2]]\n",
    "        if (any(name in item[0] for name in sandwich_dir_names)):\n",
    "            sandwich_files += filenames\n",
    "        else:\n",
    "            not_sandwich_files += filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n",
      "8000\n"
     ]
    }
   ],
   "source": [
    "train_split = 0.8\n",
    "val_split = 0.1\n",
    "sandwich_train_index = [0 for i in range(0, int(len(sandwich_files)*train_split), 1)]\n",
    "sandwich_train_index += [1 for i in range(int(len(sandwich_files)*train_split), int(len(sandwich_files)*(train_split+val_split)), 1)]\n",
    "sandwich_train_index += [2 for i in range(int(len(sandwich_files)*(train_split+val_split)), len(sandwich_files), 1)]\n",
    "\n",
    "#use sandwich_train_index size so that we have balanced dataset\n",
    "not_sandwich_train_index = [0 for i in range(0, int(len(sandwich_files)*train_split), 1)]\n",
    "not_sandwich_train_index += [1 for i in range(int(len(sandwich_files)*train_split), int(len(sandwich_files)*(train_split+val_split)), 1)]\n",
    "not_sandwich_train_index += [2 for i in range(int(len(sandwich_files)*(train_split+val_split)), len(sandwich_files), 1)]\n",
    "\n",
    "\n",
    "random.shuffle(sandwich_train_index)\n",
    "random.shuffle(not_sandwich_train_index)\n",
    "random.shuffle(not_sandwich_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copied 1000 files.\n",
      "copied 1000 files.\n",
      "copied 1000 files.\n",
      "copied 1000 files.\n",
      "copied 1000 files.\n",
      "copied 1000 files.\n",
      "copied 1000 files.\n",
      "copied 1000 files.\n",
      "copied 1000 files\n",
      "copied 1000 files\n",
      "copied 1000 files\n",
      "copied 1000 files\n",
      "copied 1000 files\n",
      "copied 1000 files\n",
      "copied 1000 files\n",
      "copied 1000 files\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(sandwich_train_index), 1):\n",
    "    output_directory = '../data/images/test/sandwich'\n",
    "    if sandwich_train_index[i] == 0:\n",
    "        output_directory = '../data/images/train/sandwich'\n",
    "    elif sandwich_train_index[i] == 1:\n",
    "        output_directory = '../data/images/val/sandwich'\n",
    "    source_path = os.path.join(sandwich_files[i][0], sandwich_files[i][1])\n",
    "    dest_path = os.path.join(output_directory, sandwich_files[i][1])\n",
    "    \n",
    "    if (os.path.isfile(dest_path)):\n",
    "        raise ValueError('File already exists.')\n",
    "    \n",
    "    shutil.copyfile(source_path, dest_path)\n",
    "    \n",
    "for i in range(0, len(not_sandwich_train_index), 1):\n",
    "    output_directory = '../data/images/test/not_sandwich'\n",
    "    if not_sandwich_train_index[i] == 0:\n",
    "        output_directory = '../data/images/train/not_sandwich'\n",
    "    elif not_sandwich_train_index[i] == 1:\n",
    "        output_directory = '../data/images/val/not_sandwich'\n",
    "    source_path = os.path.join(not_sandwich_files[i][0], not_sandwich_files[i][1])\n",
    "    dest_path = os.path.join(output_directory, not_sandwich_files[i][1])\n",
    "    \n",
    "    if (os.path.isfile(dest_path)):\n",
    "        raise ValueError('File already exists.')\n",
    "    \n",
    "    shutil.copyfile(source_path, dest_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
